{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Time Analysis (BETA)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### READ BEFORE STARTING:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### YOU HAVE TO SET UP YOUR LOG FILES TO RUN THIS CODE.\n",
    "#### Option 1) Editing submit.py so all trained models output their logs in a location for the program.\n",
    "1) Open submit.py, and go to line 64 (Or find the line that starts with f'log... it should be around line 60-65 if I'm wrong)\n",
    "2) Change that line to the following: ```f'log = {os.path.join(\"condor\", \"logs\", f\"{args.model_name}.log\")}',```\n",
    "3) Retrain any models and gain access to their logs\n",
    "#### Option 2) Manually input the logs yourself\n",
    "1) Open the terminal, and ssh into submit\n",
    "2) Run the following command: ```/scratch/YOUR_NAME/icetop-cnn/condor/logs/``` (Take note of the YOUR_NAME field, be sure to change it!)\n",
    "3) Run ```ls``` to see all of the logs\n",
    "4) Once you've found a log you want to copy, run the following command: ```cat DESIRED_LOG.log``` (This will display all the file contents)\n",
    "5) Keep the terminal open. On the left-hand side of the screen, navigate to: ```./home/YOUR_NAME/icetop-cnn/condor```\n",
    "6) Once there, create a new folder named ```logs```\n",
    "7) Open up the new directory, and create a new file ```DESIRED_LOG.log```, where DESIRED_LOG is the same name of the log you opened on the terminal\n",
    "8) Open the new file, copy the contents in the terminal, and paste into the new log file\n",
    "9) Repeat for all logs desired, and now update submit.py so you never have to do this again!\n",
    "\n",
    "#### THIS IS A BETA!! If you encounter any bugs or errors please report them to me!!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import Required Modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import json\n",
    "import os\n",
    "from glob import glob\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "from utils import get_cuts, get_event_parameters, get_training_assessment_cut\n",
    "\n",
    "from datetime import datetime as dt\n",
    "from datetime import timedelta as td"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model and Assessment Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The keys will be the names of the models you wish to analyze.\n",
    "# The values will be the nuclei to assess for each model.\n",
    "MODEL_NAMES_AND_NUCLEI = {\n",
    "    'comp_baseline': 'phof',\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training Resource Consumption"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Access the Condor Logs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[]\n"
     ]
    }
   ],
   "source": [
    "# Get the directory of where all the logs are located\n",
    "LOG_DIR = os.path.join(os.getcwd(), 'condor', 'logs')\n",
    "\n",
    "# Get every log file within the user's home directory with it's file path\n",
    "ALL_LOGS = glob(os.path.join(LOG_DIR, '*.log'))\n",
    "\n",
    "# Create a second list that only contains the name of the model pertaining to said log\n",
    "LOG_NAMES = []\n",
    "for log in ALL_LOGS:\n",
    "    LOG_NAMES.append(log[log.rfind('/')+1:log.find('.log')])\n",
    "\n",
    "# Create a third list that only contains the logs of the models that are being assessed \n",
    "MODEL_LOGS = sorted(set(LOG_NAMES).intersection(MODEL_NAMES_AND_NUCLEI))\n",
    "print(MODEL_LOGS)\n",
    "# Create a list of file objects of each log\n",
    "# Exists as a function so time and memory can be ran seperately while still properly closing files after opening\n",
    "def get_log_files():\n",
    "    LOG_FILES = []\n",
    "    for log in MODEL_LOGS:\n",
    "        LOG_FILES.append(\n",
    "            open(LOG_DIR +'/'+log+'.log')\n",
    "        )\n",
    "    return LOG_FILES"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Assess Time Needed to Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Take in the file\n",
    "#Take this time: 005 (238358931.000.000) 2025-09-11 21:57:58 Job terminated.\n",
    "##Which is seen right above the run-time stats\n",
    "#And subtract it from: 040 (238358931.000.000) 2025-09-11 19:19:24 Started transferring input files\n",
    "##Which is when files start being transfered \n",
    "\n",
    "# Track what job is currently being worked on \n",
    "jobCount = 1\n",
    "# Create list to store dicts of modelNameJobNum and CPU Time\n",
    "JOB_INFO = []\n",
    "# Go model by model \n",
    "for file in get_log_files():\n",
    "    # On new file, reset variables to inital state\n",
    "    jobCount = 1\n",
    "    # Go line by line \n",
    "    for line in file.readlines():\n",
    "        # Get the start time\n",
    "        if line.find(\"Started transferring input files\") != -1:  \n",
    "            #Calculate year, month, day of the start\n",
    "            year  = int(line[ line.find('-')-4 :  line.find('-')    ])\n",
    "            month = int(line[ line.find('-')+1 : line.rfind('-')    ]) \n",
    "            day   = int(line[line.rfind('-')+1 : line.rfind('-') + 3])\n",
    "            #Calculate hour, minute, second of the start\n",
    "            hr    = int(line[ line.find(':')-2 :  line.find(':')    ])\n",
    "            mn    = int(line[ line.find(':')+1 : line.rfind(':')    ])\n",
    "            sc    = int(line[line.rfind(':')+1 : line.rfind(':') + 3])\n",
    "            #Create the datetime object for the start\n",
    "            startTime = dt(year, month, day, hr, mn, sc)        \n",
    "        # Get the end time\n",
    "        elif line.find(\"Job terminated\") != -1 and line.find(\"of its own accord\") == -1:\n",
    "            #Calculate year, month, day of the end\n",
    "            year  = int(line[ line.find('-')-4 :  line.find('-')    ])\n",
    "            month = int(line[ line.find('-')+1 : line.rfind('-')    ]) \n",
    "            day   = int(line[line.rfind('-')+1 : line.rfind('-') + 3])\n",
    "            #Calculate hour, minute, second of the end\n",
    "            hr    = int(line[ line.find(':')-2 :  line.find(':')    ])\n",
    "            mn    = int(line[ line.find(':')+1 : line.rfind(':')    ])\n",
    "            sc    = int(line[line.rfind(':')+1 : line.rfind(':') + 3])\n",
    "            #Create the datetime object for the end\n",
    "            endTime = dt(year, month, day, hr, mn, sc-1)\n",
    "\n",
    "            #Calculate the time difference between endTime and startTime\n",
    "            CPUTime = endTime - startTime;\n",
    "            #Get the name of the file\n",
    "            fileName= file.name[file.name.rfind('/')+1:file.name.find('.log')]\n",
    "            #Append a dictionary into JOB_INFO\n",
    "            JOB_INFO.append({\n",
    "                \"modelAndJob\" : fileName + \", Iteration \"+str(jobCount),\n",
    "                \"CPUTimeSeconds\" : CPUTime.total_seconds()\n",
    "            })\n",
    "            #Iterate jobCount\n",
    "            jobCount+=1\n",
    "        # If the line doesn't have data that we want\n",
    "    # Close the file\n",
    "    file.close()\n",
    "\n",
    "for job in JOB_INFO:\n",
    "    print(\"Time to train \" + job[\"modelAndJob\"] + \":\")\n",
    "    print(\"\\tCPU Runtime: \" + str(td(seconds=job[\"CPUTimeSeconds\"])))\n",
    "    print()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "IceTop-CNN",
   "language": "python",
   "name": "icetop-cnn"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
